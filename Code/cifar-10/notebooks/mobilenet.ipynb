{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "mobilenet.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "accelerator": "GPU",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "aH_XOXnlaIDq",
    "colab_type": "code",
    "pycharm": {
     "is_executing": false
    },
    "colab": {}
   },
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "\n",
    "from easydict import EasyDict\n",
    "import tensorflow_datasets as tfds\n",
    "from datetime import datetime\n",
    "print(tf.__version__)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-2AmFNAAjns-",
    "colab_type": "code",
    "pycharm": {
     "is_executing": false
    },
    "colab": {}
   },
   "source": [
    "# For faster training, GPU should be available. Go to: Editor->Notebook settings and select the hardware acceleration (TPU does not work atm)\n",
    "print(\"GPU Available: \", tf.test.is_gpu_available())"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9rFsQHzmhHT7",
    "colab_type": "code",
    "pycharm": {
     "is_executing": false
    },
    "colab": {}
   },
   "source": [
    "# Installing newest version of tensorflow_hub otherwise we get an error\n",
    "!pip install --upgrade tensorflow_hub\n",
    "import tensorflow_hub as hub\n",
    "hub.__version__"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "i4A8eBs0bDPb",
    "colab_type": "code",
    "pycharm": {
     "is_executing": false
    },
    "colab": {}
   },
   "source": [
    "IMG_SIZE = 96\n",
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "basemodel_path = \"mobilenet\""
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "y94F7R-Jai9U",
    "colab_type": "code",
    "pycharm": {
     "is_executing": false
    },
    "colab": {}
   },
   "source": [
    "def ld_cifar():\n",
    "    def format_example(image, label):\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "        image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
    "        return image, label\n",
    "\n",
    "    BATCH_SIZE = 128\n",
    "    train_split_weights = (9, 1)\n",
    "    train_split = tfds.Split.TRAIN.subsplit(weighted=train_split_weights)\n",
    "    test_split = tfds.Split.TEST.subsplit(weighted=(1,))\n",
    "    (raw_train, raw_validation, raw_test), metadata = tfds.load('cifar10', split=list(train_split + test_split),\n",
    "                                                                with_info=True,\n",
    "                                                                as_supervised=True)\n",
    "\n",
    "    train_batches = raw_train.map(format_example).shuffle(1000).batch(BATCH_SIZE).repeat()\n",
    "    validation_batches = raw_validation.map(format_example).batch(BATCH_SIZE).repeat()\n",
    "    test_batches = raw_test.map(format_example).batch(BATCH_SIZE)\n",
    "\n",
    "    num_train, num_validation = (\n",
    "        metadata.splits['train'].num_examples * weight / 10\n",
    "        for weight in train_split_weights\n",
    "    )\n",
    "\n",
    "    num_test = metadata.splits['test'].num_examples\n",
    "\n",
    "    train_steps = round(num_train) // BATCH_SIZE\n",
    "    validation_steps = round(num_validation) // BATCH_SIZE\n",
    "    test_steps = round(num_test) // BATCH_SIZE\n",
    "    \n",
    "    steps_dict = EasyDict(train_steps=train_steps, validation_steps=validation_steps, test_steps=test_steps)\n",
    "    return EasyDict(train=train_batches, validation=validation_batches, test=test_batches,\n",
    "                    steps=steps_dict)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "L4TFpNygapo0",
    "colab_type": "code",
    "pycharm": {
     "is_executing": false
    },
    "colab": {}
   },
   "source": [
    "def main():\n",
    "    data = ld_cifar()    \n",
    "    feature_extractor_layer = tf.keras.applications.MobileNetV2(include_top=False, weights='imagenet', input_shape=IMG_SHAPE)\n",
    "    feature_extractor_layer.trainable = False\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        feature_extractor_layer,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dropout(0.5),     \n",
    "        tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    opt = tf.keras.optimizers.SGD()\n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['acc'])\n",
    "    \n",
    "    now = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    log_dir = \"./\" + basemodel_path + \"_logs/fit/\" + now\n",
    "    checkpoint_path = log_dir + \"/weights/\" + basemodel_path + \"_weights\"\n",
    "    \n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir + \"/tensorboard\")\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_weights_only=True, save_best_only=True, verbose=True)\n",
    "\n",
    "    model.fit(data.train, epochs=50, steps_per_epoch=data.steps.train_steps, validation_data=data.validation, validation_steps=data.steps.validation_steps, callbacks=[tensorboard_callback, es_callback, cp_callback])\n",
    "    model.load_weights(checkpoint_path) # Load best model\n",
    "    model.evaluate(data.test, steps=data.steps.test_steps)\n",
    "    "
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "L8jiEuiiauJL",
    "colab_type": "code",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "colab": {}
   },
   "source": [
    "main()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "O47rluHohZco",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Helper to zip and download weights\n",
    "def zip_and_download_logs():\n",
    "  try:\n",
    "    !zip -r logs.zip mobilenet_logs\n",
    "#     from google.colab import files Works better to download tham manually\n",
    "#     files.download('logs.zip') \n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "zip_and_download_logs()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rZQUwZ52iUTg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Helper\n",
    "def remove_created_files():\n",
    "  import shutil\n",
    "  import os\n",
    "  shutil.rmtree(\"./mobilenet_logs\")\n",
    "  os.remove(\"./logs.zip\")\n",
    "# remove_created_files()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iK_TPOfLiGYz",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Training with TPU. Does not work atm since it is still in experimental stage.\n",
    "# tpu_strategy = tf.distribute.experimental.TPUStrategy()\n",
    "# with tpu_strategy.scope():\n",
    "#   main()"
   ],
   "execution_count": 0,
   "outputs": []
  }
 ]
}